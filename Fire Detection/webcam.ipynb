{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "796d3132",
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = 'Laptop.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "49d11b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "class PiVideoStream:\n",
    "    def __init__(self, resolution=(920, 768), framerate=32):\n",
    "        # initialize the camera and stream\n",
    "        self.camera = VideoStream()\n",
    "        self.camera.resolution = resolution\n",
    "        self.camera.framerate = framerate\n",
    "        self.rawCapture = PiRGBArray(self.camera, size=resolution)\n",
    "        self.stream = self.camera.capture_continuous(self.rawCapture,\n",
    "            format=\"bgr\", use_video_port=True)\n",
    "\n",
    "        # initialize the frame and the variable used to indicate\n",
    "        # if the thread should be stopped\n",
    "        self.frame = None\n",
    "        self.stopped = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25fd2c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start(self):\n",
    "        # start the thread to read frames from the video stream\n",
    "        Thread(target=self.update, args=()).start()\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc03e00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(self):\n",
    "        # keep looping infinitely until the thread is stopped\n",
    "        for f in self.stream:\n",
    "            # grab the frame from the stream and clear the stream in\n",
    "            # preparation for the next frame\n",
    "            self.frame = f.array\n",
    "            self.rawCapture.truncate(0)\n",
    "\n",
    "            # if the thread indicator variable is set, stop the thread\n",
    "            # and resource camera resources\n",
    "            if self.stopped:\n",
    "                self.stream.close()\n",
    "                self.rawCapture.close()\n",
    "                self.camera.close()\n",
    "                return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35d98fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read(self):\n",
    "        # return the frame most recently read\n",
    "        return self.frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49ed8ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop(self):\n",
    "        # indicate that the thread should be stopped\n",
    "        self.stopped = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcd91844",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoStream:\n",
    "    def __init__(self, src=0, usePiCamera=False, resolution=(320, 240),\n",
    "        framerate=32):\n",
    "        # check to see if the picamera module should be used\n",
    "        if usePiCamera:\n",
    "            # only import the picamera packages unless we are\n",
    "            # explicity told to do so -- this helps remove the\n",
    "            # requirement of `picamera[array]` from desktops or\n",
    "            # laptops that still want to use the `imutils` package\n",
    "            from pivideostream import PiVideoStream\n",
    " \n",
    "            # initialize the picamera stream and allow the camera\n",
    "            # sensor to warmup\n",
    "            self.stream = PiVideoStream(resolution=resolution,\n",
    "                framerate=framerate)\n",
    " \n",
    "        # otherwise, we are using OpenCV so initialize the webcam\n",
    "        # stream\n",
    "        else:\n",
    "            self.stream = WebcamVideoStream(src=src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94622239",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start(self):\n",
    "        # start the threaded video stream\n",
    "        return self.stream.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43c2b424",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(self):\n",
    "        # grab the next frame from the stream\n",
    "        self.stream.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de45331d",
   "metadata": {},
   "outputs": [],
   "source": [
    " def read(self):\n",
    "        # return the current frame\n",
    "        return self.stream.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82d50540",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop(self):\n",
    "        # stop the thread and release any resources\n",
    "        self.stream.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60a7a49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imutils in c:\\users\\mamoo\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (0.5.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7e68bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pygame in c:\\users\\mamoo\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (2.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ab29062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.2 (SDL 2.0.18, Python 3.9.12)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "from pygame import mixer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57f9e886",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import imutils\n",
    "import keras\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.models import load_model\n",
    "from imutils.video import VideoStream\n",
    "from imutils.video import FPS\n",
    "from threading import Thread\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import datetime\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7a184e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# initialize the total number of frames that *consecutively* contain fire\n",
    "# along with threshold required to trigger the fire alarm\n",
    "TOTAL_CONSEC = 0\n",
    "TOTAL_THRESH = 5\n",
    "# initialize the fire alarm\n",
    "FIRE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69357997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading model...\n"
     ]
    }
   ],
   "source": [
    "# load the model\n",
    "print(\"[INFO] loading model...\")\n",
    "MODEL_PATH = 'D:/project/xception_final.h5'\n",
    "model = keras.models.load_model(MODEL_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ddb3c6bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] starting video stream...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [24]\u001b[0m, in \u001b[0;36m<cell line: 14>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# classify the input image and initialize the label and\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# probability of the prediction\u001b[39;00m\n\u001b[0;32m     26\u001b[0m begin \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 27\u001b[0m (fire, notFire) \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     28\u001b[0m terminate \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     30\u001b[0m label \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot Fire\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\training.py:1978\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1976\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mon_predict_begin()\n\u001b[0;32m   1977\u001b[0m batch_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1978\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, iterator \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39menumerate_epochs():  \u001b[38;5;66;03m# Single epoch.\u001b[39;00m\n\u001b[0;32m   1979\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mcatch_stop_iteration():\n\u001b[0;32m   1980\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39msteps():\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\data_adapter.py:1190\u001b[0m, in \u001b[0;36mDataHandler.enumerate_epochs\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21menumerate_epochs\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1189\u001b[0m   \u001b[38;5;124;03m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1190\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_truncate_execution_to_epoch():\n\u001b[0;32m   1191\u001b[0m     data_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset)\n\u001b[0;32m   1192\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial_epoch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_epochs):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\contextlib.py:119\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\data_adapter.py:1206\u001b[0m, in \u001b[0;36mDataHandler._truncate_execution_to_epoch\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1202\u001b[0m \u001b[38;5;124;03m\"\"\"Truncates steps per execution to at most one epoch.\"\"\"\u001b[39;00m\n\u001b[0;32m   1203\u001b[0m should_truncate \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1204\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m   1205\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_steps)\n\u001b[1;32m-> 1206\u001b[0m original_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_steps_per_execution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m   1207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1208\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m should_truncate:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:674\u001b[0m, in \u001b[0;36mBaseResourceVariable.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnumpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    673\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 674\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    675\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    676\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy() is only available when eager execution is enabled.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# initialize the video stream and allow the camera sensor to warm up\n",
    "print(\"[INFO] starting video stream...\")\n",
    "vs = VideoStream(src=0).start()\n",
    "#vs = VideoStream(usePiCamera=True).start()\n",
    "time.sleep(2.0)\n",
    "start = time.time()\n",
    "#fps = FPS().start()\n",
    "f = 0\n",
    "\n",
    "# loop over the frames from the video stream\n",
    "while True:\n",
    "    # grab the frame from the threaded video stream and resize it\n",
    "    # to have a maximum width of 400 pixels\n",
    "    frame = vs.read()\n",
    "    #A variable f to keep track of total number of frames read\n",
    "    f += 1\n",
    "    frame = imutils.resize(frame, width=400)\n",
    "    # prepare the image to be classified by our deep learning network\n",
    "    image = cv2.resize(frame, (299, 299))\n",
    "    image = image.astype(\"float\") / 255.0\n",
    "    image = img_to_array(image)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    " \n",
    "    # classify the input image and initialize the label and\n",
    "    # probability of the prediction\n",
    "    begin = time.time()\n",
    "    (fire, notFire) = model.predict(image)[0]\n",
    "    terminate = time.time()\n",
    "\n",
    "    label = \"Not Fire\"\n",
    "    proba = notFire\n",
    "    # check to see if fire was detected using our convolutional\n",
    "    # neural network\n",
    "    if fire > notFire:\n",
    "        # update the label and prediction probability\n",
    "        label = \"Fire\"\n",
    "        proba = fire\n",
    " \n",
    "        # increment the total number of consecutive frames that\n",
    "        # contain fire\n",
    "        TOTAL_CONSEC += 1\n",
    "        if not FIRE and TOTAL_CONSEC >= TOTAL_THRESH:\n",
    "            # indicate that fire has been found\n",
    "            FIRE = True\n",
    "            #CODE FOR NOTIFICATION SYSTEM HERE\n",
    "\t    #A siren will be played indefinitely on the speaker\n",
    "            mixer.init()\n",
    "            mixer.music.load('siren.mp3')\n",
    "            mixer.music.play(-1)\n",
    "            # otherwise, reset the total number of consecutive frames and the\n",
    "    # fire alarm\n",
    "    else:\n",
    "        TOTAL_CONSEC = 0\n",
    "        FIRE = False\n",
    "        \n",
    "        # build the label and draw it on the frame\n",
    "    label = \"{}: {:.2f}%\".format(label, proba * 100)\n",
    "    frame = cv2.putText(frame, label, (10, 25),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "\n",
    "    # show the output frame\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    #fps.update()\n",
    " \n",
    "    # if the `q` key was pressed, break from the loop\n",
    "    if key == ord(\"q\"):\n",
    "        print(\"[INFO] classification took {:.5} seconds\".format(terminate - begin))\n",
    "        end = time.time()\n",
    "        break\n",
    "\n",
    "# do a bit of cleanup\n",
    "print(\"[INFO] cleaning up...\")\n",
    "seconds = end - start\n",
    "print(\"Time taken : {0} seconds\".format(seconds))\n",
    "fps  = f/ seconds\n",
    "print(\"Estimated frames per second : {0}\".format(fps))\n",
    "#fps.stop()\n",
    "#print(\"[INFO] elasped time: {:.2f}\".format(fps.elapsed()))\n",
    "#print(\"[INFO] approx. FPS: {:.2f}\".format(fps.fps()))\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "vs.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75958d19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
